<div align="center">

<img src='./assets/logo_new.png' width=40%/>

<!-- # Open Agentic Video Intelligence -->
<br>

**ğŸŒŸ Comprehensive Video Intelligence: An All-in-One Framework for Understanding, Editing, and Remaking**

<div align="center">

</div>

<a href='https://space.bilibili.com/3546868449544308'><img src="https://img.shields.io/badge/bilibili-00A1D6.svg?logo=bilibili&logoColor=white" /></a>&nbsp;
<a href='https://www.youtube.com/@AI-Creator-is-here'><img src='https://badges.aleen42.com/src/youtube.svg' /></a>&nbsp;

</div>

<div align="center">
	
[English](readme.md) | [ç®€ä½“ä¸­æ–‡](readme_zh.md)

</div>

---

## ğŸ“¹ **Demo Video**
<div>
<a href="https://www.youtube.com/watch?v=JZkXO1NG2Ok" target='_blank'><img src="assets/overview.png" width="100%"></a>
</div>

In this video, we demonstrate how to use VideoAgent to:
- Clearly articulate user requirements
- Achieve â€‹intent analysis and â€‹autonomous tool use & planning
- Create â€‹multi-modal products, including detailed workflows
- Fully automatic generation of video overview

## ğŸš€ Key Features

ğŸ§  - **Understanding Video Content**<br>
Enable in-depth analysis, summarization, and insight extraction from video media with advanced multi-modal intelligence capabilities.

âœ‚ï¸ - **Editing Video Clips**<br>
Provide intuitive tools for assembling, clipping, and reconfiguring content with seamless workflow integration.

ğŸ¨ - **Remaking Creative Videos**<br>
Utilize generative technologies to produce new, imaginative video content through AI-powered creative assistance.

ğŸ”§ - **Multi-Modal Agentic Framework**<br>
Deliver comprehensive video intelligence through an integrated framework that combines multiple AI modalities for enhanced performance.

ğŸš€ - **Seamless Natural Language Experience**<br>
Transform video interaction and creation through pure conversational AI - no complex interfaces or technical expertise required, just natural dialogue with VideoAgent.

 
```mermaid
graph TB
    A[ğŸ¬ VideoAgent Framework] --> B[ğŸ§  Video Understanding & Summarization]
    A --> C[âœ‚ï¸ Video Editing]
    A --> D[ğŸ¨ VIdeo Remaking]
    
    B --> B1[Video Q&A]
    B --> B2[Video Summarization]
    
    C --> C1[Movie Edits]
    C --> C2[Commentary Video]
    C --> C3[Video Overview]
    
    D --> D1[Meme Videos]
    D --> D2[Music Videos]
    D --> D3[Cross-Cultural Comedy]
```

</div>

---

## ğŸ“‘ Table of Contents

- [ğŸŒŸ System Overview](#system-overview)
- [ğŸ”§ Evaluation](#evaluation)
- [ğŸš€ Quick Start](#quick-start)
- [ğŸ”® Demos](#demos)
- [ğŸ’– Acknowledgments](#acknowledgments)


### ğŸ”¥ **Why VideoAgent?**

| ğŸ§  **Easy-to-Use** | ğŸš€ **Boundless Creativity** | ğŸ¨ **High-Quality** |
|:---:|:---:|:---:|
| One-Prompt Video Creation | Create From Any Ideas | Human-Quality Video Production |
| Transform your ideas into professional videos | Workflow generation for your unique ideas | Deliver videos that meet professional standards |

---

## ğŸŒŸSystem Overview

Our system introduces three key innovations for automated video processing. **Intent Analysis** captures both explicit and implicit sub-intents beyond user commands. **Autonamous Tool Use & Planning** employs graph-powered workflow generation with adaptive feedback loops for automated agent orchestration. **Multi-Modal Understanding** transforms raw input into semantically aligned visual queries for enhanced retrieval.

### ğŸ§  **Intent Analysis**
	
- ğŸ” VideoAgent intelligently **decomposes user instructions** into both **explicit and implicit sub-intents**, capturing nuanced requirements that users may not explicitly state. This advanced parsing ensures **comprehensive understanding** of user goals beyond surface-level commands.

- ğŸ¯ Through an **intent-to-agent mapping mechanism**, the system identifies precisely which capabilities within the multi-agent framework are needed. This targeted approach enables **efficient activation** of relevant system components while avoiding unnecessary computational overhead for **optimal task execution**.

### ğŸ”§ **Autonomous Tool Use & Planning**

- âš™ï¸ **A graph-powered framework** automatically translates user intents into **executable workflows**. The system dynamically selects appropriate agents and constructs optimal execution sequences. Nodes represent tool capabilities while edges define workflow connections for complex video tasks.

- ğŸ”„ Adaptive feedback loops continuously refine the planning process through **two-step self-evaluation**. This ensures robust **automated decision-making** and seamless execution. The system **self-corrects** and optimizes performance throughout the entire task lifecycle.

### ğŸ¬ **Multi-Modal Understanding**

- ğŸ“‹ **The Storyboard Agent** transforms raw user input into **optimized visual queries**. It first analyzes pre-captioned video material banks to understand available resources. This foundational analysis ensures the system knows exactly what content is accessible for query processing.

- ğŸ’¡ The agent then **decomposes user input** into **fine-grained sub-queries** that are both visually and semantically aligned. This sophisticated breakdown enables **enhanced video retrieval** by matching user intentions with the most relevant visual content in the database.

---

## ğŸ”§Evaluation
We conduct extensive experiments across multiple dimensions to validate the effectiveness of VideoAgent in addressing key challenges.

### Boundless Creativity via Workflow Construction

To evaluate VideoAgent's **boundless creativity** through automatic workflow construction, we compared five broadly applicable agents across three backbone models. Our findings demonstrate that VideoAgent significantly outperforms other baselines on the Audio and Video datasets, showcasing its **creative workflow generation capabilities** through graph-structured guidance and self-reflection driven by dedicated self-evaluation feedback. Furthermore, we observe that VideoAgent exhibits superior and more stable **creative performance** under the Claude 3.7 backbone compared to GPT-4o and Deepseek-v3, while other baseline methods show fluctuations across different backbones. This highlights VideoAgent's ability to **unleash boundless creativity** by automatically constructing diverse and effective workflows that adapt to various user requirements, with more capable LLMs achieving deeper comprehension and providing more robust creative solutions for complex graph-based tasks.

<div align="center">
    <img src='./assets/eval1_audio_new.png' /><br>
    <img src='./assets/eval1_video_new.png' /><br>
</div>

### Superior Multimodal Understanding

To validate our multimodal understanding capabilities, we conducted text-to-video retrieval experiments using shuffled caption queries. The evaluation employs three metrics to assess our model's ability to retrieve corresponding visual content: Recall measures the model's ability to correctly reorder shuffled video clips by comparing retrieved clip midpoints against ground truth positions; Embedding Matching-based score assesses coarse-grained alignment between generated videos and high-level caption summaries; and Intersection over Union quantifies temporal alignment accuracy at the clip level by computing the ratio of temporal overlap to total coverage between retrieved and ground truth intervals. The experimental results demonstrate that our approach can retrieve more accurate video segments, thereby showcasing our precise multimodal understanding capabilities.


<div align="center">
    <img src='./assets/eva2.png' /><br>
</div>


### More Iterations, Better Performance

We investigate VideoAgent's iterative refinement capabilities by analyzing the impact of reflection rounds on performance. Through comprehensive hyperparameter experiments on workflow composition across two datasets using three LLM backbones, we demonstrate VideoAgent's **notable self-improvement ability**. The results reveal that while early iterations produce baseline results, our system's **adaptive reflection mechanism** drives significant performance gains with each subsequent round. VideoAgent achieves **consistent workflow composition success rates of 0.95** across all tested configurations, showcasing its **robust self-correction capabilities** and **reliable high-quality output** regardless of the underlying LLM backbone.
<div align="center">
    <div style="display: flex; justify-content: center; width: 80%; flex-wrap: nowrap;">
        <img src='./assets/eva3.jpg' style="margin: 0 5px; width: 400px;" />
	<img src='./assets/eva4.jpg' style="margin: 0 5px; width: 400px;" />
    </div>
</div>

---

## ğŸš€Quick Start

### ğŸ–¥ï¸ **Environment**

```
GPU Memory: 8GB  
OS: Linux, Windows
```

### ğŸ“¥ **Clone and Install**

```bash
git clone https://github.com/HKUDS/VideoAgent.git
conda create --name videoagent python=3.10
conda activate videoagent
conda install -y -c conda-forge pynini==2.1.5 ffmpeg
pip install -r requirements.txt
```

### ğŸ“¦ **Model Download**

```bash
# Download CosyVoice
cd tools/CosyVoice
huggingface-cli download PillowTa1k/CosyVoice --local-dir pretrained_models
```

```bash
# Download fish-speech
cd tools/fish-speech
huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5
```

```bash
# Download seed-vc
cd tools/seed-vc
huggingface-cli download PillowTa1k/seed-vc --local-dir checkpoints
```

```bash
# Download DiffSinger
cd tools/DiffSinger
huggingface-cli download PillowTa1k/DiffSinger --local-dir checkpoints
```

```bash
# Download Whisper
cd tools
huggingface-cli download openai/whisper-large-v3-turbo --local-dir whisper-large-v3-turbo
```

```bash
# Make sure git-lfs is installed (https://git-lfs.com)
git lfs install
```

```bash
# Download ImageBind
cd tools
mkdir .checkpoints
cd .checkpoints
wget https://dl.fbaipublicfiles.com/imagebind/imagebind_huge.pth
```

**ğŸŒŸ Multiple models are available for your convenience; you may wish to download only those relevant to your project.**


<table>
  <tr>
    <th align="center">Feature Type</th>
    <th align="center">Video Demo</th>
    <th align="center">Required Models</th>
  </tr>
  <tr>
    <td align="center">Cross Talk</td>
    <td align="center">English Stand-up Comedy to Chinese Crosstalk</td>
    <td align="center">CosyVoice, Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">Talk Show</td>
    <td align="center">Chinese Crosstalk to English Stand-up Comedy</td>
    <td align="center">CosyVoice, Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">MAD TTS</td>
    <td align="center">Xiao-Ming-Jian-Mo(å°æ˜å‰‘é­”) Meme</td>
    <td align="center">fish-speech</td>
  </tr>
  <tr>
    <td align="center">MAD SVC</td>
    <td align="center">AI Music Videos</td>
    <td align="center">DiffSinger, seed-vc, Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">Rhythm</td>
    <td align="center">Spider-Man: Across the Spider-Verse</td>
    <td align="center">Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">Comm</td>
    <td align="center">Commentary Video</td>  
    <td align="center">CosyVoice, Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">News</td>
    <td align="center">Tech News: OpenAI's GPT-4o Image Generation Release</td>
    <td align="center">CosyVoice, Whisper, ImageBind</td>
  </tr>
  <tr>
    <td align="center">Video QA/Summarization</td>
    <td align="center">Dune 2 Movie Cast Update Podcast</td>
    <td align="center">Whisper</td>
  </tr>
</table>

</div>

### ğŸ¤– **LLM Configuration**

```bash
# VideoAgent\environment\config\config.yml
# Applicable scenarios and LLM configuration
# Claude is required as it powers the Agentic Graph Router 
llm:
  # Video Remixing/TTS/SVC/Stand-up/CrossTalk
  deepseek_api_key: ""  
  deepseek_base_url: ""  

  # Agentic Graph Router/TTS/SVC/Stand-up/CrossTalk
  claude_api_key: ""  
  claude_base_url: ""

  # Video Editing/Overview/Summarization/QA/Commentary Video
  gpt_api_key: ""  
  gpt_base_url: ""  

  # MLLM for caption and fine-grained video understanding
  gemini_api_key: ""  
  gemini_base_url: ""  
```

### ğŸ¯ **Usage**

```bash
# With the configuration now complete, proceed to run the following instructions:
python main.py
# The console will output:
User Requirement: ...
# Requirement Example:
# 1. I need to create a reworded version of an existing video where the speech content is modified while maintaining the original speaker's voice. The video should have the same visuals as the original, but with updated dialogue that follows my specific requirements.
# 2. I have a standup comedy script that I'd like to turn into a professional-looking video. I need the script to be performed with good comedic timing and audience reactions, then matched with relevant video footage to create a complete standup comedy special. I already have a reference script and some footage I want to use for the video.
```
The current LLM selections are optimized for each function.

You can also adjust the model names in `VideoAgent\environment\config\llm.py` if needed.

---

## ğŸ”®Demos

<table>
<tr>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV1C9Z6Y3ESo/" target='_blank'><img src="assets/spiderman_cover.png" width="100%"></a>
Movie Edits
</td>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV1ucZ6YmEBU/" target='_blank'><img src="assets/masterma_cover.png" width="100%"></a>
Meme Videos
</td>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV1t8ZCYsEeA/" target='_blank'><img src="assets/airencuoguo_cover.png" width="100%"></a>
Music Videos
</td>
</tr>
<tr>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV1ucZ6YmESg/" target='_blank'><img src="assets/adapted_crosstalk_cover.png" width="100%"></a>
Verbal Comedy Arts
</td>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV1TmZ6YjEvV/" target='_blank'><img src="assets/joylife_cover.png" width="100%"></a>
Commentary Video
</td>
<td align="center" width="33%">
<a href="https://www.bilibili.com/video/BV12mZ6YLEqW/" target='_blank'><img src="assets/openai_news_cover.png" width="100%"></a>
Video Overview
</td>
</tr>
</table>

For additional demo usage details, please refer to:  
ğŸ‘‰ [Demos Documentation](demos_documents.md)


You can find more fun videos on our Bilibili channel here:  
ğŸ‘‰ [Bilibili Homepage](https://space.bilibili.com/3546868449544308)  
Feel free to check it out for more entertaining content! ğŸ˜Š


**Note**: All videos are used for research and demonstration purposes only. The audio and visual assets are sourced from the Internet. Please contact us if you believe any content infringes upon your intellectual property rights.

---

## ğŸ’–**Acknowledgments**

We express our deepest gratitude to the numerous individuals and organizations that have made VideoAgent possible. This framework stands on the shoulders of giants, benefiting from the collective wisdom of the open-source community and the groundbreaking work of researchers worldwide.

### ğŸ”§ **Open-Source Community and Service Providers**

- [CosyVoice](https://github.com/FunAudioLLM/CosyVoice)
- [Fish Speech](https://github.com/fishaudio/fish-speech)
- [Seed-VC](https://github.com/Plachtaa/seed-vc)
- [DiffSinger](https://github.com/MoonInTheRiver/DiffSinger)
- [VideoRAG](https://github.com/HKUDS/VideoRAG)
- [ImageBind](https://github.com/facebookresearch/ImageBind)
- [Whisper](https://github.com/openai/whisper)
- [Librosa](https://github.com/librosa/librosa)


### ğŸ¨ **Content Creators and Inspiration**

Our work has been significantly enriched by the creative contributions of content creators across various platforms. We acknowledge:

- ğŸ¬ **Content Creators**: The talented creators behind the original video content used for testing and demonstration
- ğŸ­ **Comedy Artists**: Those whose work inspired our cross-cultural adaptations  
- ğŸ¥ **Filmmakers**: The production teams behind the movies and TV shows featured in our demos

**âš ï¸ Note**: All content used in our demonstrations is for research purposes only. We deeply respect the intellectual property rights of all content creators and welcome any concerns or feedback regarding content usage.

---

<div align="center">
<img src="https://visitor-badge.laobi.icu/badge?page_id=HKUDS.Open-NotebookLM&style=for-the-badge&color=00d4ff" alt="Visitors">
</div>


---------------------------


Giá»›i thiá»‡u Dá»± Ã¡n VideoAgent
1. VideoAgent lÃ  gÃ¬?
VideoAgent lÃ  má»™t framework mÃ£ nguá»“n má»Ÿ giÃºp báº¡n tá»± Ä‘á»™ng hiá»ƒu ná»™i dung video, chá»‰nh sá»­a video, vÃ  sÃ¡ng táº¡o láº¡i video báº±ng cÃ´ng nghá»‡ trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘a phÆ°Æ¡ng thá»©c (AI Ä‘a modal).
Báº¡n cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i há»‡ thá»‘ng chá»‰ báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn, khÃ´ng cáº§n ká»¹ thuáº­t phá»©c táº¡p, dá»… dÃ¹ng cho cáº£ ngÆ°á»i má»›i.

2. VideoAgent lÃ m Ä‘Æ°á»£c gÃ¬?
CÃ¡c tÃ­nh nÄƒng chÃ­nh:
Hiá»ƒu video:
PhÃ¢n tÃ­ch, tÃ³m táº¯t, trÃ­ch xuáº¥t Ã½ chÃ­nh tá»« ná»™i dung video (vÃ­ dá»¥: tráº£ lá»i cÃ¢u há»i vá» video, tÃ³m táº¯t ná»™i dung video, v.v.).

Chá»‰nh sá»­a video:
Cáº¯t ghÃ©p, láº¯p rÃ¡p, lÃ m láº¡i cÃ¡c Ä‘oáº¡n video theo yÃªu cáº§u chá»‰ báº±ng cÃ¡ch nháº­p mÃ´ táº£ Ã½ tÆ°á»Ÿng.

SÃ¡ng táº¡o láº¡i video:
Táº¡o ra video má»›i, ná»™i dung sÃ¡ng táº¡o dá»±a trÃªn AI nhÆ° video meme, video Ã¢m nháº¡c, cháº¿ láº¡i ká»‹ch báº£n, v.v.

Tráº£i nghiá»‡m há»™i thoáº¡i tá»± nhiÃªn:
Chá»‰ cáº§n mÃ´ táº£ Ã½ tÆ°á»Ÿng hoáº·c yÃªu cáº§u báº±ng tiáº¿ng Anh/Tiáº¿ng Trung (hoáº·c ngÃ´n ngá»¯ Ä‘Ã£ há»— trá»£), há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng hiá»ƒu vÃ  thá»±c hiá»‡n.

Má»™t sá»‘ á»©ng dá»¥ng ná»•i báº­t:
Chuyá»ƒn Ä‘á»•i ká»‹ch báº£n hÃ i Anh - Trung vÃ  ngÆ°á»£c láº¡i

Biáº¿n video standup comedy thÃ nh meme

Táº¡o video Ã¢m nháº¡c AI

Táº¡o video bÃ¬nh luáº­n, báº£n tin, podcast tÃ³m táº¯t phim, v.v.

3. CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a VideoAgent
VideoAgent dÃ¹ng cÃ¡c mÃ´ hÃ¬nh AI máº¡nh máº½ nhÆ° Claude, GPT, DeepSeek, Geminiâ€¦ Ä‘á»ƒ:

PhÃ¢n tÃ­ch Ã½ Ä‘á»‹nh:
Tá»± Ä‘á»™ng bÃ³c tÃ¡ch Ã½ Ä‘á»‹nh cá»§a báº¡n (dÃ¹ diá»…n Ä‘áº¡t trá»±c tiáº¿p hay giÃ¡n tiáº¿p), sau Ä‘Ã³ xÃ¡c Ä‘á»‹nh cÃ´ng cá»¥, workflow phÃ¹ há»£p.

Tá»± lÃªn káº¿ hoáº¡ch workflow:
Dá»±a vÃ o biá»ƒu Ä‘á»“ tÃ¡c vá»¥ (graph workflow), chá»n agent (tÃ¡c nhÃ¢n) thÃ­ch há»£p cho tá»«ng bÆ°á»›c, tá»± pháº£n há»“i & tá»‘i Æ°u quÃ¡ trÃ¬nh.

Hiá»ƒu ná»™i dung Ä‘a phÆ°Æ¡ng thá»©c:
Káº¿t há»£p phÃ¢n tÃ­ch cáº£ hÃ¬nh áº£nh, Ã¢m thanh, vÄƒn báº£nâ€¦ Äáº·c biá»‡t cÃ³ â€œStoryboard Agentâ€ giÃºp phÃ¢n tÃ­ch tÃ i nguyÃªn video cÃ³ sáºµn vÃ  chia nhá» yÃªu cáº§u thÃ nh cÃ¡c truy váº¥n phÃ¹ há»£p.

4. DÃ nh cho ai?
Báº¡n muá»‘n tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh xá»­ lÃ½ video (hiá»ƒu â€“ chá»‰nh sá»­a â€“ sÃ¡ng táº¡o láº¡i) mÃ  khÃ´ng cáº§n ká»¹ nÄƒng code phá»©c táº¡p.

Táº¡o ná»™i dung sÃ¡ng táº¡o, biáº¿n Ã½ tÆ°á»Ÿng thÃ nh video chuyÃªn nghiá»‡p chá»‰ qua há»™i thoáº¡i.

PhÃ¹ há»£p cho cáº£ ngÆ°á»i má»›i, nhÃ  sÃ¡ng táº¡o ná»™i dung, nhÃ³m truyá»n thÃ´ng, nghiÃªn cá»©u AI vá» xá»­ lÃ½ video Ä‘a modal.

5. CÃ¡ch cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng (TÃ³m táº¯t nhanh)
a. YÃªu cáº§u há»‡ thá»‘ng
MÃ¡y cÃ³ GPU â‰¥ 8GB (khuyÃªn dÃ¹ng)

Windows hoáº·c Linux

b. CÃ¡c bÆ°á»›c cÃ i Ä‘áº·t
Clone repo

bash
Sao chÃ©p
Chá»‰nh sá»­a
git clone https://github.com/HKUDS/VideoAgent.git
Táº¡o mÃ´i trÆ°á»ng Python

bash
Sao chÃ©p
Chá»‰nh sá»­a
conda create --name videoagent python=3.10
conda activate videoagent
CÃ i thÆ° viá»‡n

bash
Sao chÃ©p
Chá»‰nh sá»­a
conda install -y -c conda-forge pynini==2.1.5 ffmpeg
pip install -r requirements.txt
Táº£i cÃ¡c mÃ´ hÃ¬nh AI cáº§n thiáº¿t
(CosyVoice, fish-speech, seed-vc, DiffSinger, Whisper, ImageBind, v.v.)
Má»—i tÃ­nh nÄƒng cáº§n mÃ´ hÃ¬nh khÃ¡c nhau â€“ báº¡n chá»‰ cáº§n táº£i nhá»¯ng mÃ´ hÃ¬nh cho má»¥c Ä‘Ã­ch báº¡n dÃ¹ng (Ä‘Ã£ cÃ³ hÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c trong README).

Äiá»n API key cho cÃ¡c mÃ´ hÃ¬nh LLM (Claude, GPT, Deepseek, Gemini) trong file cáº¥u hÃ¬nh.

Cháº¡y thá»­

bash
Sao chÃ©p
Chá»‰nh sá»­a
python main.py
Khi cháº¡y, há»‡ thá»‘ng sáº½ há»i â€œUser Requirementâ€ â€“ báº¡n chá»‰ cáº§n nháº­p mÃ´ táº£ yÃªu cáº§u vá» video.

VÃ­ dá»¥:
"Táº¡o video meme báº±ng giá»ng nÃ³i cá»§a tÃ´i vÃ  ghÃ©p cáº£nh vui nhá»™n."

"TÃ³m táº¯t ná»™i dung chÃ­nh cá»§a video nÃ y vÃ  tráº£ lá»i má»™t sá»‘ cÃ¢u há»i."

6. Demo & TÃ i liá»‡u tham kháº£o
Tham kháº£o video hÆ°á»›ng dáº«n vÃ  demo táº¡i YouTube hoáº·c Bilibili.

Xem chi tiáº¿t cÃ¡c use case trong má»¥c Demos Documentation cá»§a repo.

7. Káº¿t luáº­n
VideoAgent giÃºp tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh xá»­ lÃ½ video tá»« hiá»ƒu â€“ chá»‰nh sá»­a â€“ sÃ¡ng táº¡o láº¡i, sá»­ dá»¥ng AI tiÃªn tiáº¿n, thao tÃ¡c qua há»™i thoáº¡i tá»± nhiÃªn.

ThÃ­ch há»£p cho cáº£ ngÆ°á»i má»›i báº¯t Ä‘áº§u láº«n dÃ¢n chuyÃªn.

Chá»‰ cáº§n nháº­p Ã½ tÆ°á»Ÿng, má»i thá»© cÃ²n láº¡i há»‡ thá»‘ng lo!

--------------------------------------------
1. Tá»•ng quan Triá»ƒn khai VideoAgent dÆ°á»›i dáº¡ng WebApp
Má»¥c tiÃªu:
Báº¡n muá»‘n cÃ i Ä‘áº·t VideoAgent trÃªn má»™t mÃ¡y chá»§ (server), táº¡o giao diá»‡n web Ä‘á»ƒ ngÆ°á»i dÃ¹ng upload video, nháº­p yÃªu cáº§u vÃ  nháº­n káº¿t quáº£ (hiá»ƒu, chá»‰nh sá»­a, táº¡o video má»›i...)
Dá»¯ liá»‡u cÃ³ thá»ƒ lÆ°u trá»¯ riÃªng tÆ°, báº£o máº­t, khÃ´ng phá»¥ thuá»™c cloud cÃ´ng cá»™ng nhÆ° Google Colab hay HuggingFace Spaces.

2. CÃ¡c thÃ nh pháº§n cáº§n cÃ³ khi triá»ƒn khai WebApp
Backend (mÃ¡y chá»§ AI):
Cháº¡y cÃ¡c mÃ´ hÃ¬nh AI, xá»­ lÃ½ video/audio/ná»™i dung, nháº­n yÃªu cáº§u tá»« web, tráº£ káº¿t quáº£.

Frontend (giao diá»‡n web):
Cho phÃ©p ngÆ°á»i dÃ¹ng upload video, nháº­p yÃªu cáº§u, theo dÃµi tiáº¿n trÃ¬nh, nháº­n káº¿t quáº£.

Database (tÃ¹y chá»n):
LÆ°u log, user, lá»‹ch sá»­ task náº¿u cáº§n.

Háº¡ táº§ng lÆ°u trá»¯:
Chá»— chá»©a video gá»‘c, káº¿t quáº£ Ä‘áº§u ra (thÆ°á»ng lÃ  á»• cá»©ng lá»›n).

3. YÃªu cáº§u pháº§n cá»©ng cá»¥ thá»ƒ
A. Cáº¥u hÃ¬nh tá»‘i thiá»ƒu
CPU: 8 vCPU trá»Ÿ lÃªn

RAM: Tá»‘i thiá»ƒu 32 GB

á»” cá»©ng: SSD 512 GB â€“ 1 TB (tÃ¹y lÆ°á»£ng video xá»­ lÃ½)

GPU:

Tá»‘i thiá»ƒu: NVIDIA RTX 3060 12GB (1 card)

Khuyáº¿n nghá»‹: RTX 3090 24GB / A5000 / A6000 (xá»­ lÃ½ nhanh, Ä‘a user)

LÃ½ do: MÃ´ hÃ¬nh nhÆ° Whisper large-v3-turbo, DiffSinger, cÃ¡c model xá»­ lÃ½ video/audio náº·ng Ä‘á»u cáº§n nhiá»u VRAM.

Há»‡ Ä‘iá»u hÃ nh: Ubuntu 20.04/22.04 (á»•n Ä‘á»‹nh), cÃ i Ä‘áº·t Python, CUDA, driver NVIDIA Ä‘áº§y Ä‘á»§.

B. Náº¿u nhiá»u ngÆ°á»i dÃ¹ng Ä‘á»“ng thá»i
ThÃªm GPU:

CÃ ng nhiá»u user cÃ ng cáº§n nhiá»u GPU hoáº·c GPU máº¡nh.

1 card 24GB cÃ³ thá»ƒ phá»¥c vá»¥ ~2-4 user song song náº¿u tÃ¡c vá»¥ phá»©c táº¡p (transcribe, synthesize, remix video, v.v).

RAM: NÃªn tÄƒng lÃªn 64GB hoáº·c hÆ¡n náº¿u cháº¡y nhiá»u model/multi-process.

4. Chi phÃ­ triá»ƒn khai mÃ¡y chá»§
A. PhÆ°Æ¡ng Ã¡n thuÃª cloud server cÃ³ GPU (khuyáº¿n nghá»‹ cho ngÆ°á»i má»›i)
Lá»±a chá»n phá»• biáº¿n:
AWS EC2 g4dn.xlarge/g5.xlarge

Google Cloud A2-highgpu

Vultr, Paperspace, LambdaLabs, OVH, Hetzner (cÃ³ thuÃª server GPU giÃ¡ tá»‘t hÆ¡n)

VÃ­ dá»¥: AWS EC2 g4dn.2xlarge
GPU: NVIDIA T4 16GB

vCPU: 8

RAM: 32GB

SSD: 100GB

GiÃ¡:

Theo giá»: ~$1/giá» (xáº¥p xá»‰ 24â€“30 USD/ngÃ y)

Theo thÃ¡ng: ~$750â€“900 USD/thÃ¡ng (cháº¡y liÃªn tá»¥c)

CÃ³ thá»ƒ giáº£m phÃ­ báº±ng Spot Instance hoáº·c chá»‰ báº­t khi dÃ¹ng.

Náº¿u cáº§n GPU máº¡nh hÆ¡n (RTX 3090, A100, v.v.)
Paperspace: ~1.5â€“3 USD/giá» (A100, RTX 4090)

LambdaLabs: ~0.99â€“2.5 USD/giá»

OVH, Hetzner: Chá»‰ tá»« 200â€“400 USD/thÃ¡ng (RTX 3090, RAM 64GB, NVMe 1TB)

TÃ­nh toÃ¡n chi phÃ­:
Nháº¹ (1â€“2 user/lÆ°á»£t): GPU T4/3060, chi phÃ­ tá»« 300â€“700 USD/thÃ¡ng

Vá»«a (3â€“5 user): GPU 3090/4090 hoáº·c A100, phÃ­ tá»« 700â€“1500 USD/thÃ¡ng

Cao (8+ user): Cluster nhiá»u GPU, phÃ­ tá»« 1500â€“5000 USD/thÃ¡ng

ChÆ°a tÃ­nh phÃ­ bandwidth (táº£i/stream video lá»›n sáº½ tá»‘n thÃªm phÃ­ cloud)
B. Mua mÃ¡y chá»§ váº­t lÃ½ (cho dá»± Ã¡n lá»›n, lÃ¢u dÃ i)
MÃ¡y tráº¡m workstation cÅ© (RTX 3090/4090, RAM 64GB): ~40â€“70 triá»‡u VNÄ/mÃ¡y (~1600â€“2800 USD)

Server doanh nghiá»‡p (A6000, A100): ~200 triá»‡u â€“ 1 tá»· VNÄ trá»Ÿ lÃªn

C. PhÃ­ váº­n hÃ nh khÃ¡c
TÃªn miá»n, báº£o máº­t, backup: ~5â€“20 USD/thÃ¡ng

DevOps triá»ƒn khai (náº¿u khÃ´ng tá»± lÃ m): thuÃª ngoÃ i 10â€“30 triá»‡u VNÄ (setup, maintain web)

5. Gá»£i Ã½ cÃ´ng nghá»‡ WebApp + cÃ¡ch triá»ƒn khai
Backend:

Sá»­ dá»¥ng FastAPI hoáº·c Flask (Python) lÃ m API trung gian giá»¯a web vÃ  cÃ¡c mÃ´ hÃ¬nh AI

Xá»­ lÃ½ cÃ¡c tÃ¡c vá»¥ náº·ng thÃ´ng qua Celery (background task), trÃ¡nh ngháº½n server khi nhiá»u user gá»­i request.

Frontend:

ReactJS, NextJS, hoáº·c Ä‘Æ¡n giáº£n lÃ  Flask/Streamlit UI cho MVP (prototyping nhanh)

LÆ°u trá»¯:

Káº¿t há»£p AWS S3 hoáº·c local disk náº¿u báº£o máº­t riÃªng tÆ°.

CÃ¡ch báº£o máº­t:

Háº¡n cháº¿ upload file Ä‘á»™c háº¡i, phÃ¢n quyá»n user, SSL, tÃ¡ch biá»‡t mÃ´i trÆ°á»ng dev/prod.

6. Báº£ng tÃ³m táº¯t chi phÃ­ cÆ¡ báº£n
Cáº¥u hÃ¬nh	Sá»‘ user	Cloud (theo thÃ¡ng)	Server váº­t lÃ½ (1 láº§n)
T4/3060, 32GB RAM	1â€“2	300â€“700 USD	~40â€“50 triá»‡u VNÄ
3090/4090, 64GB RAM	3â€“5	700â€“1500 USD	~70â€“100 triá»‡u VNÄ
>A100, 128GB RAM	8+	1500â€“5000 USD	>200 triá»‡u VNÄ

7. Máº¹o tiáº¿t kiá»‡m & khá»Ÿi Ä‘á»™ng nhanh
Chá»‰ báº­t server khi cáº§n xá»­ lÃ½ batch lá»›n, táº¯t khi khÃ´ng dÃ¹ng (cloud hourly billing)

Äáº§u tÆ° mÃ¡y váº­t lÃ½ náº¿u xÃ¡c Ä‘á»‹nh váº­n hÃ nh lÃ¢u dÃ i, á»•n Ä‘á»‹nh, khÃ´ng ngáº¡i tá»± váº­n hÃ nh/IT

Tá»‘i Æ°u hoÃ¡ mÃ£ nguá»“n, phÃ¢n quyá»n queue, khÃ´ng cho 1 user â€œchiáº¿m háº¿tâ€ tÃ i nguyÃªn

8. Káº¿t luáº­n
VideoAgent ráº¥t â€œngá»‘nâ€ GPU (vÃ¬ pháº£i cháº¡y nhiá»u model AI lá»›n), cÃ ng nhiá»u user thÃ¬ cÃ ng cáº§n pháº§n cá»©ng máº¡nh.

ThuÃª server cloud lÃ  giáº£i phÃ¡p Ä‘Æ¡n giáº£n nháº¥t, chi phÃ­ tÃ¹y sá»‘ user vÃ  cÆ°á»ng Ä‘á»™ xá»­ lÃ½.

Náº¿u chá»‰ thá»­ nghiá»‡m ná»™i bá»™ hoáº·c cho 1â€“2 user, hoÃ n toÃ n dÃ¹ng Ä‘Æ°á»£c GPU 12â€“16GB.

Náº¿u chÆ°a cÃ³ kinh nghiá»‡m DevOps, nÃªn báº¯t Ä‘áº§u tá»« cloud, sau quen hÃ£y build server riÃªng.

KhÃ´ng nÃªn triá»ƒn khai lÃªn shared hosting/thÆ°á»ng, VPS yáº¿u sáº½ khÃ´ng Ä‘á»§ tÃ i nguyÃªn cháº¡y model AI!
